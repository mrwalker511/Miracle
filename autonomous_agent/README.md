# Autonomous Coding Agent

An autonomous AI agent that writes code iteratively until tests pass, learning from failures using vector similarity.

## ğŸ¯ Mission

Build an autonomous agent that:
- Accepts coding tasks as goals (not prompts)
- Writes code iteratively in a loop
- Generates and runs tests automatically
- Learns from failures using vector similarity
- Doesn't stop until code is functional or max iterations reached

**"The difference between a chatbot and an agent is the loop."**

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ORCHESTRATOR                  â”‚
â”‚    (State Machine Controller)           â”‚
â”‚                                         â”‚
â”‚  INIT â†’ PLANNING â†’ CODING â†’ TESTING    â”‚
â”‚              â†‘            |              â”‚
â”‚              â””â”€REFLECTINGâ”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚     â”‚      â”‚     â”‚
    â”Œâ”€â”€â”€â”€â–¼â” â”Œâ”€â”€â–¼â”€â”€â” â”Œâ–¼â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚PLAN â”‚ â”‚CODE â”‚ â”‚TESTâ”‚ â”‚ REFLECT â”‚
    â”‚ NER â”‚ â”‚  R  â”‚ â”‚ ER â”‚ â”‚   OR    â”‚
    â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚     â”‚      â”‚     â”‚
         â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â–¶ MEMORY
                              (PostgreSQL + pgvector)
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Docker & Docker Compose
- OpenAI API key

### Installation

1. **Clone the repository**
   ```bash
   cd autonomous_agent
   ```

2. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env and set:
   # - OPENAI_API_KEY=your_key_here
   # - DB_PASSWORD=secure_password
   ```

4. **Start PostgreSQL with pgvector**
   ```bash
   docker-compose up -d postgres
   ```

5. **Initialize database**
   ```bash
   python scripts/setup_db.py
   ```

### Running a Task

Python task:
```bash
python -m src.main run --language python --task "Build a REST API for managing todo items with SQLite"
```

Node.js task:
```bash
python -m src.main run --language node --task "Build a Node.js CLI tool that prints the current time"
```

Or interactive mode:
```bash
python -m src.main run
```

### View Task History

```bash
python -m src.main history
```

## ğŸ“ Project Structure

```
autonomous_agent/
â”œâ”€â”€ config/                 # Configuration files (YAML)
â”‚   â”œâ”€â”€ settings.yaml      # System settings
â”‚   â”œâ”€â”€ database.yaml      # Database config
â”‚   â”œâ”€â”€ openai.yaml        # OpenAI API config
â”‚   â”œâ”€â”€ system_prompts.yaml # Agent prompts
â”‚   â””â”€â”€ allowed_deps.json  # Dependency allowlist
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py           # CLI entry point
â”‚   â”œâ”€â”€ orchestrator.py   # State machine controller
â”‚   â”œâ”€â”€ config_loader.py  # Config management
â”‚   â”œâ”€â”€ agents/           # Specialized agents
â”‚   â”‚   â”œâ”€â”€ planner.py    # Task decomposition
â”‚   â”‚   â”œâ”€â”€ coder.py      # Code generation
â”‚   â”‚   â”œâ”€â”€ tester.py     # Test generation & execution
â”‚   â”‚   â””â”€â”€ reflector.py  # Error analysis
â”‚   â”œâ”€â”€ llm/              # LLM interface
â”‚   â”‚   â”œâ”€â”€ openai_client.py  # Flexible OpenAI client
â”‚   â”‚   â”œâ”€â”€ tools.py          # Function calling tools
â”‚   â”‚   â””â”€â”€ token_counter.py  # Usage tracking
â”‚   â”œâ”€â”€ memory/           # Database & vector store
â”‚   â”‚   â”œâ”€â”€ db_manager.py     # PostgreSQL operations
â”‚   â”‚   â””â”€â”€ vector_store.py   # Similarity search
â”‚   â”œâ”€â”€ sandbox/          # Code execution
â”‚   â”‚   â”œâ”€â”€ safety_checker.py # AST + Bandit scanning
â”‚   â”‚   â””â”€â”€ docker_executor.py # Sandbox management
â”‚   â”œâ”€â”€ ui/               # User interface
â”‚   â”‚   â”œâ”€â”€ cli.py        # Rich terminal UI
â”‚   â”‚   â””â”€â”€ logger.py     # Structured logging
â”‚   â””â”€â”€ utils/            # Utilities
â”‚       â”œâ”€â”€ circuit_breaker.py # Prevent infinite loops
â”‚       â””â”€â”€ metrics_collector.py # Performance tracking
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_db.py       # Database initialization
â”‚   â””â”€â”€ init_db.sql       # Schema definition
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ sandbox/workspace/    # Generated code workspace
â”œâ”€â”€ logs/                 # Structured JSON logs
â”œâ”€â”€ docker-compose.yml    # PostgreSQL + pgvector
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Model Selection

Edit `config/openai.yaml` to use different models:

```yaml
models:
  planner: "gpt-4-turbo-preview"
  coder: "gpt-4-turbo-preview"
  tester: "gpt-4-turbo-preview"
  reflector: "gpt-4-turbo-preview"
  embedding: "text-embedding-3-large"
```

Supports any OpenAI model: `gpt-4`, `gpt-4-turbo`, `gpt-3.5-turbo`, etc.

### Iteration Limits

Edit `config/settings.yaml`:

```yaml
orchestrator:
  max_iterations: 15
  circuit_breaker:
    warning_threshold: 12
    hard_stop: 15
```

### Safety Rules

Edit `config/settings.yaml`:

```yaml
safety:
  block_operations:
    - "eval"
    - "exec"
    - "compile"
```

## ğŸ§  How It Works

### The Loop

1. **PLANNING**: Agent analyzes the task, queries past patterns, creates subtasks
2. **CODING**: Agent writes code using available tools (create_file, read_file, etc.)
3. **TESTING**: Agent generates pytest tests (including hypothesis property tests) and executes them
4. **REFLECTING**: If tests fail, agent analyzes errors, searches for similar past failures, proposes fixes
5. **Loop**: Returns to CODING with hypothesis â†’ repeat until tests pass or max iterations

### Learning from Failures

- Every failure is stored with a vector embedding
- When a new error occurs, vector similarity search finds similar past failures
- Agent uses past solutions to inform current fixes
- Successful patterns are stored for future tasks

### Safety

- **AST scanning**: Blocks dangerous operations (`eval`, `exec`, etc.)
- **Bandit integration**: Security vulnerability scanning
- **Sandbox isolation**: Code runs in restricted Docker containers
- **Dependency approval**: User must approve package installations

## ğŸ“Š Database Schema

PostgreSQL with pgvector extension:

- **tasks**: Main task tracking
- **iterations**: Detailed loop cycle logs
- **failures**: Error memory with embeddings
- **patterns**: Successful solution templates
- **metrics**: Performance data
- **approvals**: User decision tracking

## ğŸ¯ Example Usage

### REST API Task

```bash
python -m src.main run -t "Create a Flask REST API for managing books with SQLite" -p web_app
```

### Data Processing Task

```bash
python -m src.main run -t "Build a script to parse CSV files and generate statistics" -p data_pipeline
```

### CLI Tool Task

```bash
python -m src.main run -t "Create a CLI tool for managing TODO items stored in JSON" -p cli_tool
```

## ğŸ” Monitoring

### Logs

Structured JSON logs in `logs/agent.log`:

```json
{
  "timestamp": "2025-01-13T10:30:45.123Z",
  "level": "INFO",
  "task_id": "abc-123",
  "iteration": 3,
  "phase": "testing",
  "event": "test_execution_complete",
  "data": {"passed": 8, "failed": 2}
}
```

### Metrics

Track performance in database:
- Iteration duration
- Token usage per phase
- Test pass rate
- Error type frequency
- Pattern match effectiveness

## ğŸš§ Current Limitations

- **Languages**: Python and Node.js (JavaScript)
- **Testing**: pytest (Python) and node:test (Node.js)
- **Dependencies**: Manual installation required (no auto-install)
- **Sandbox**: Basic Docker isolation (can be enhanced)

## ğŸ”® Future Enhancements

- [ ] More languages (TypeScript, Go, etc.)
- [ ] Parallel execution of subtasks
- [ ] Cost optimization (model selection based on task complexity)
- [ ] Web UI dashboard
- [ ] Collaborative learning across agent instances
- [ ] Fine-tuning based on success metrics

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ¤ Contributing

Contributions welcome! Please see CONTRIBUTING.md for guidelines.

## ğŸ“§ Support

For issues and questions:
- GitHub Issues: [github.com/yourrepo/issues](https://github.com/yourrepo/issues)
- Documentation: See `docs/` folder

## ğŸ™ Acknowledgments

Built with:
- OpenAI API (GPT-4, text-embedding-3-large)
- PostgreSQL + pgvector
- Python 3.11+
- Rich (terminal UI)
- pytest + hypothesis (testing)

---

**Remember: "The difference between a chatbot and an agent is the loop."**
